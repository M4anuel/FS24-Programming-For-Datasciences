{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Week 4 - Assignment</center></h2>\n",
    "<h3><center>Programming for Data Science 2024</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the topics covered in the fourth lecture.\n",
    "\n",
    "The exercise will be marked as passed if you get **at least 10/15** points.\n",
    "\n",
    "Exercises must be handed in via **ILIAS** (Homework assignments). Deliver your submission as a compressed file (zip) containing one .py or .ipynb file with all exercises. The name of both the .zip and the .py/.ipynb file **must** be *SurnameName* of the two members of the group. Example: Riccardo Cusinato + Athina Tzovara = *CusinatoRiccardo_TzovaraAthina.zip* .\n",
    "\n",
    "It's important to use comments to explain your code and show that you're able to take ownership of the exercises and discuss them.\n",
    "\n",
    "You are not expected to collaborate outside of the group on exercises and submitting other groupsâ€™ code as your own will result in 0 points.\n",
    "\n",
    "For questions contact: *riccardo.cusinato@unibe.ch* with the subject: *Programming for Data Science 2024*.\n",
    "\n",
    "**Deadline: 14:00, March 21, 2024.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 1 - Create Dataframes<span style=\"float: right\">5 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame *episodes_df* with the columns **ses**, **ep**, and **title**, as below:\n",
    "\n",
    "|**ses**|**ep**|**title**|\n",
    "|:---|:---|:---|\n",
    "|1|1|One|\n",
    "|1|2|Two|\n",
    "|2|1|Three|\n",
    "|2|2|Four|\n",
    "\n",
    "Create a DataFrame *imdb_df* with the columns **ses**, **ep**, and **score**, as below:\n",
    "\n",
    "|**ses**|**ep**|**score**|\n",
    "|:---|:---|:---|\n",
    "|1|1|8.4|\n",
    "|1|2|8.1|\n",
    "|2|1|7.9|\n",
    "|2|2|7.7|\n",
    "\n",
    "Merge the two DataFrames. Then, find and print the title of the episode with the higest score.\n",
    "\n",
    "**NB**: To merge the two dataframes you have to use the *merge* method:\n",
    "```python\n",
    "merged_df = episodes_df.merge(imdb_df, on=['ses', 'ep'])\n",
    "```\n",
    "\n",
    "\n",
    "1. By manipulating the dataframes, find and print the title of the episode with the higest score. (*3 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  title\n",
      "0   One\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ses = {0: 1, 1: 1, 2: 2, 3: 2}\n",
    "ep = {0: 1, 1: 2, 2: 1, 3: 2}\n",
    "title = {0: \"One\", 1: \"Two\", 2: \"Three\", 3: \"Four\"}\n",
    "score = {0: 8.4, 1: 8.1, 2: 7.9, 3: 7.7}\n",
    "\n",
    "episodes_df : pd.DataFrame = pd.DataFrame({\"ses\": ses, \"ep\": ep, \"title\": title})\n",
    "imdb_df : pd.DataFrame = pd.DataFrame({\"ses\": ses, \"ep\": ep, \"score\": score})\n",
    "\n",
    "merged_df: pd.DataFrame = episodes_df.merge(imdb_df, on = [\"ses\", \"ep\"])\n",
    "\n",
    "max_score = merged_df.max()[\"score\"]\n",
    "a = merged_df.loc[merged_df.score == max_score,[\"title\"]]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Change the **score** of the entry with the title \"Three\" in the DataFrame you created in Task 1 and print the result. The new score should be 6. (*2 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArithmeticError\n",
      "   ses  ep  title  score\n",
      "0    1   1    One    8.4\n",
      "1    1   2    Two    8.1\n",
      "2    2   1  Three    6.0\n",
      "3    2   2   Four    7.7\n"
     ]
    }
   ],
   "source": [
    "merged_df.at[merged_df.index[merged_df[\"title\"] == \"Three\"].tolist()[0], \"score\"] = 6\n",
    "\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 2 - Load DataFrames<span style=\"float: right\">6 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the two CSV files 'silicon_valley_episodes.csv' and 'silicon_valley_imdb.csv', found in the \"data\" directory, as DataFrames. Merge the two DataFrames as in the first task, using **season** and **episode_num** as keys to merge on. (*2 points*)\n",
    "```python\n",
    "episodes_df = pd.read_csv('./data/silicon_valley_episodes.csv')\n",
    "imdb_df = pd.read_csv('./data/silicon_valley_imdb.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_df = pd.read_csv('./data/silicon_valley_episodes.csv')\n",
    "imdb_df = pd.read_csv('./data/silicon_valley_imdb.csv')\n",
    "merged_df: pd.DataFrame = episodes_df.merge(imdb_df, on = [\"season\", \"episode_num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new DataFrame, called **df_best**, containing only the episodes with an **imdb_rating** at or above 9. Use the DataFrame created in the previous task as a starting point. (*2 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    season  episode_num  episode_num_overall                        title_x  \\\n",
      "7        1            8                    8  Optimal Tip-To-Tip Efficiency   \n",
      "17       2           10                   18         Two Days of the Condor   \n",
      "45       5            8                   46              Fifty-One Percent   \n",
      "\n",
      "   directed_by written_by original_air_date_x  us_viewers  \\\n",
      "7   Mike Judge  Alec Berg            01.06.14     1740000   \n",
      "17   Alec Berg  Alec Berg            14.06.15     2110000   \n",
      "45   Alec Berg  Alec Berg            13.05.18      707000   \n",
      "\n",
      "                          title_y original_air_date_y  imdb_rating  \\\n",
      "7   Optimal Tip-To-Tip Efficiency         1 Jun. 2014          9.3   \n",
      "17         Two Days of the Condor        14 Jun. 2015          9.2   \n",
      "45              Fifty-One Percent         13 May 2018          9.1   \n",
      "\n",
      "    total_votes                                               desc  \n",
      "7          3627  Pied Piper makes it to the next stage of Disru...  \n",
      "17         2320  The verdict on Pied Piper's fate coincides wit...  \n",
      "45         2128  PiperNet launches, but an early success makes ...  \n"
     ]
    }
   ],
   "source": [
    "best_df: pd.DataFrame = merged_df[(merged_df.imdb_rating >= 9)]\n",
    "print(best_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find mean number of **us_viewers** for episodes with an IMDB score greater than or equal to 9, and for episodes with an IMDB score lower than 9, and print the means. (*2 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us_viewers    1519000.0\n",
      "dtype: float64\n",
      "us_viewers    1234000.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean = best_df[[\"us_viewers\"]].mean()\n",
    "bad_df = pd.concat([merged_df, best_df]).drop_duplicates(keep = False)\n",
    "mean2 = bad_df[[\"us_viewers\"]].mean()\n",
    "print(mean)\n",
    "print(mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 3 - DataFrames Ufuncs<span style=\"float: right\">4 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the two dataframe *df1* and *df2* with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    np.arange(1, 10).reshape(3, 3),\n",
    "    columns=[\"a\", \"b\", \"c\"],\n",
    "    index=[\"1\", \"2\", \"3\"]\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    np.arange(1, 10).reshape(3, 3) / 2,\n",
    "    columns=[\"a\", \"b\", \"d\"],\n",
    "    index=[\"1\", \"2\", \"4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add the two dataframes together, with the appropriate pandas method, and print the result. (*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of adding the two DataFrames:\n",
      "     a    b    c    d\n",
      "1  1.5  3.0  3.0  1.5\n",
      "2  6.0  7.5  6.0  3.0\n",
      "3  7.0  8.0  9.0  NaN\n",
      "4  3.5  4.0  NaN  4.5\n"
     ]
    }
   ],
   "source": [
    "df_sum = df1.add(df2, fill_value=0)\n",
    "print(\"Result of adding the two DataFrames:\")\n",
    "print(df_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add the underlying numpy objects of the two dataframes, and print the result. (*0.5 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of adding the numpy arrays:\n",
      "[[ 1.5  3.   4.5]\n",
      " [ 6.   7.5  9. ]\n",
      " [10.5 12.  13.5]]\n"
     ]
    }
   ],
   "source": [
    "np_sum = df1.values + df2.values\n",
    "print(\"\\nResult of adding the numpy arrays:\")\n",
    "print(np_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compare the two results that you obtained and comment if and **why** they are different. (*3 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The df_sum DataFrame obtained from pandas addition includes all columns \n",
    "present in both df1 and df2. It fills missing values with zeros \n",
    "(since we specified fill_value=0), resulting in a complete DataFrame.\n",
    "The np_sum array obtained by adding the numpy arrays directly does not \n",
    "handle missing values. If an element is missing in either df1 or df2, \n",
    "it remains missing in the resulting numpy array.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
